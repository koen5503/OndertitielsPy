# SYSTEM PROMPT: OBS AI PIPELINE WITH ASYNC BUFFERING

## Goal
Build a Python 3.10+ script that converts live speech to concise, translated subtitles for OBS and YouTube CC without losing audio data.

## 1. Technical Components
- **Audio Capture:** PyAudio (Non-blocking callback mode).
- **Communication:** asyncio.Queue for thread-safe double buffering.
- **STT:** Google Cloud Speech-to-Text V2 (StreamingRecognize).
- **Translation:** Google Cloud Translation API.
- **Refinement:** Gemini 1.5 Flash (Shortens sentences > 12 words).
- **Outputs:** OBS WebSocket v5 & YouTube Caption API (HTTP POST).

## 2. Concurrency Model
- **Producer Thread:** Continuously listens to Mic and puts chunks into `audio_queue`.
- **Stream Task:** Consumes `audio_queue`, maintains a bi-directional gRPC stream to Google. 
- **Refinement Task:** Consumes 'is_final' transcripts, translates them, and runs the LLM shortener.
- **Output Task:** Dispatches results to OBS and YouTube concurrently.

## 3. Logic for Sentence Refinement
IF `len(translated_sentence.split()) > SHORTEN_THRESHOLD`:
   CALL LLM with prompt: "Rewrite this subtitle to be concise. Max 10 words. Output only the text."
ELSE:
   USE raw translation.

## 4. YouTube CC Payload
POST to `YOUTUBE_CAPTION_URL` with:
Header: `Content-Type: text/plain`
Body: `[ISO-8601-Timestamp] [Refined_Text]`

## 5. Summary Module
Every 60 seconds, take all refined sentences from the last minute and send to LLM for a 1-sentence "Stream Recap" in OBS Source 'Summary_Ticker'.

## 6. Error Handling
- Use `asyncio.gather` for outputs to ensure one slow API doesn't block the others.
- Implement exponential backoff for Google Cloud stream reconnections.
